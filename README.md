# Data-Ingestion

In this project, I designed and implemented a structured data ingestion pipeline for Retrieval-Augmented Generation (RAG) using LangChain. I began by importing and configuring the required libraries, then explored the LangChain Document schema, understanding how page_content stores raw text and metadata stores contextual information. Then i implemented ingestion for single text files using TextLoader, ensuring correct encoding, and validated the output by checking document counts and previews. You then extended this to scalable ingestion by using DirectoryLoader with glob patterns to automatically load multiple .txt files from a directory. After ingestion, I applied CharacterTextSplitter to divide large documents into manageable chunks using defined chunk_size and chunk_overlap parameters, preparing the data for downstream embedding and retrieval tasks.

In the second phase, I focused on robust PDF ingestion and preprocessing.Where I used PyPDFLoader to extract multi-page PDF content and verified page-wise extraction. To improve quality and production-readiness, I developed a custom class called SmartPdfProcessor, which performs structured cleaning (removing extra whitespace, normalizing text, filtering small/empty pages), and applies RecursiveCharacterTextSplitter for intelligent chunking based on semantic boundaries. Then I enriched each chunk with detailed metadata including page number, total pages, character count, and chunking method to enhance traceability and retrieval accuracy. Finally, i executed the full pipeline, generated structured chunks, and validated the output, creating a clean, metadata-aware dataset ready for vector embeddings and RAG-based question answering systems.
